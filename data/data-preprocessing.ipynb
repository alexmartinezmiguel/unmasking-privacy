{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf25045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f8cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIELENS = True\n",
    "LASTFM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5171947",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MOVIELENS == True:\n",
    "    # read the data\n",
    "    df = pd.read_csv('/data/ml-1m/ratings.dat', sep='::', engine='python')\n",
    "    df.columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    \n",
    "    # only consider implicit ratings: ratings larger or equal than 3 are considered positive interactions\n",
    "    threshold = 3\n",
    "    df = df[df['rating']>=threshold]\n",
    "    df['rating'] = 1\n",
    "    \n",
    "    # split train and test sets for training the RecSys\n",
    "    # leave-one-out strategy: use the last interactions (according to time stamp) of each user as test\n",
    "    test_df = pd.DataFrame()\n",
    "    for user_id in df.user_id.unique():\n",
    "        tmp = df[df['user_id']==user_id]\n",
    "        test_df = pd.concat([test_df, tmp.sort_values('timestamp').iloc[-1:]])\n",
    "    train_df = pd.concat([df,test_df]).drop_duplicates(keep=False)\n",
    "    \n",
    "    # delete users that only appear in test but not in training\n",
    "    test_users = set(test_df.user_id.unique())\n",
    "    train_users = set(train_df.user_id.unique())\n",
    "    user_to_delete = list(test_users.difference(train_users))\n",
    "    test_df = test_df[~test_df.user_id.isin(user_to_delete)]\n",
    "    \n",
    "    # save splits\n",
    "    train_df[['user_id','item_id','rating','timestamp']].to_csv('data/ml-1m/implicit_train_df.csv', index=False)\n",
    "    test_df[['user_id','item_id','rating','timestamp']].to_csv('data/ml-1m/implicit_test_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7218f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LASTFM == True:\n",
    "    df = pd.read_csv('data/lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv', sep='\\t', \n",
    "                     header=None, names=['user_id', 'timestamp', 'artist_id', 'artist_name', 'item_id', 'item_name'],\n",
    "                     on_bad_lines='skip')\n",
    "    \n",
    "    df = df.dropna()\n",
    "    df = df[['user_id','item_id','timestamp']]\n",
    "    \n",
    "    # 1.  retain only the initial occurrence of each interaction (given by the time stamp)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    unique_interactions = df.groupby(['user_id','item_id']).min().reset_index()\n",
    "    \n",
    "    # 2. 3000 most frequently ocurring songs\n",
    "    top_k = 3000\n",
    "    itemid_to_save = df.groupby('item_id').count().sort_values('user_id', ascending=False)[:top_k].index\n",
    "    df = unique_interactions[unique_interactions['item_id'].isin(itemid_to_save)]\n",
    "    \n",
    "    # 3. users with at least 20 interactions\n",
    "    min_interactions = 20\n",
    "    tmp = df.groupby('user_id').count().sort_values('item_id')\n",
    "    userid_to_save = tmp[tmp['item_id']>=min_interactions].index\n",
    "    df = df[df['user_id'].isin(userid_to_save)]\n",
    "    \n",
    "    # map item_id and user_id to numerical id for simplicity\n",
    "    map_dict_items = {item:index for index,item in enumerate(df.item_id.unique())}\n",
    "    df.replace({'item_id':map_dict_items}, inplace=True)\n",
    "    map_dict_users = {user:index for index,user in enumerate(df.user_id.unique())}\n",
    "    df.replace({'user_id':map_dict_users}, inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # split train and test sets for training the RecSys\n",
    "    # leave-one-out strategy: use the last interactions (according to time stamp) of each user as test\n",
    "    test_df = pd.DataFrame()\n",
    "    for user_id in df.user_id.unique():\n",
    "        tmp = df[df['user_id']==user_id]\n",
    "        test_df = pd.concat([test_df, tmp.sort_values('timestamp').iloc[-1:]])\n",
    "    train_df = pd.concat([df,test_df]).drop_duplicates(keep=False)\n",
    "    \n",
    "    # save splits\n",
    "    train_df[['user_id','item_id','timestamp']].to_csv('data/lastfm-dataset-1K/implicit_train_df.csv', index=False)\n",
    "    test_df[['user_id','item_id','timestamp']].to_csv('data/lastfm-dataset-1K/implicit_test_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lime-rs",
   "language": "python",
   "name": "lime-rs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
